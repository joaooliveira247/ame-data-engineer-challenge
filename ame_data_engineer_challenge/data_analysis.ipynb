{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/27 16:51:40 WARN Utils: Your hostname, IdeaPad-Gaming-3-15IHU6 resolves to a loopback address: 127.0.1.1; using 192.168.1.4 instead (on interface wlp0s20f3)\n",
      "24/06/27 16:51:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/06/27 16:51:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/27 16:51:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from core.connection import get_from_database, get_session\n",
    "\n",
    "spark = get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data from database to spark-warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|  default| communication_tools|      false|\n",
      "|  default|             company|      false|\n",
      "|  default|             country|      false|\n",
      "|  default|    operation_system|      false|\n",
      "|  default|programming_language|      false|\n",
      "|  default|resp_programming_...|      false|\n",
      "|  default|          resp_tools|      false|\n",
      "|  default|          respondent|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dw_ame = get_from_database(spark, \"information_schema.tables\")\n",
    "tables = (\n",
    "    dw_ame.select(\"table_name\")\n",
    "    .where(F.col(\"table_schema\") == \"public\")\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()\n",
    ")\n",
    "for table in tables:\n",
    "    get_from_database(spark, table).write.saveAsTable(table)\n",
    "\n",
    "spark.sql(\"SHOW TABLES;\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Qual a quantidade de respondentes de cada país?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|           country|total|\n",
      "+------------------+-----+\n",
      "|     United States|20309|\n",
      "|             India|13721|\n",
      "|           Germany| 6459|\n",
      "|    United Kingdom| 6221|\n",
      "|            Canada| 3393|\n",
      "|Russian Federation| 2869|\n",
      "|            France| 2572|\n",
      "|            Brazil| 2505|\n",
      "|            Poland| 2122|\n",
      "|         Australia| 2018|\n",
      "|       Netherlands| 1841|\n",
      "|             Spain| 1769|\n",
      "|             Italy| 1535|\n",
      "|           Ukraine| 1279|\n",
      "|            Sweden| 1164|\n",
      "|          Pakistan| 1050|\n",
      "|             China| 1037|\n",
      "|       Switzerland| 1010|\n",
      "|            Turkey| 1004|\n",
      "|            Israel| 1003|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT \n",
    "    c.name AS country, COUNT(c.name) AS total \n",
    "FROM \n",
    "    respondent r \n",
    "INNER JOIN \n",
    "    country c ON r.country_id = c.id \n",
    "GROUP BY country \n",
    "ORDER BY total DESC;\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Quantos usuários que moram em \"United States\" gostam de Windows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|Windows user's in United States|\n",
      "+-------------------------------+\n",
      "|                           7635|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT \n",
    "    count(*) AS `Windows user's in United States`\n",
    "FROM respondent r \n",
    "INNER JOIN \n",
    "    operation_system os ON r.operation_system_id = os.id \n",
    "INNER JOIN \n",
    "    country c ON r.country_id = c.id \n",
    "WHERE c.name = 'United States' AND os.name = 'Windows';\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Qual a média de salário dos usuários que moram em Israel e gostam de Linux?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|Israel linux user's salary mean|\n",
      "+-------------------------------+\n",
      "|                       16809.26|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT \n",
    "    ROUND(AVG(salary), 2) AS `Israel linux user's salary mean`\n",
    "FROM respondent r \n",
    "INNER JOIN \n",
    "    operation_system os ON r.operation_system_id = os.id \n",
    "INNER JOIN \n",
    "    country c ON r.country_id = c.id\n",
    "WHERE c.name = 'Israel' and os.name = 'Linux-based';\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Qual a média e o desvio padrão do salário dos usuários que usam Slack para cada tamanho de empresa disponível?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------------+\n",
      "|                size|salary mean|standard deviation|\n",
      "+--------------------+-----------+------------------+\n",
      "|Fewer than 10 emp...|   21037.84|          52621.87|\n",
      "|100 to 499 employees|   27616.54|          59485.82|\n",
      "|5,000 to 9,999 em...|   30055.67|          68600.93|\n",
      "|1,000 to 4,999 em...|   30874.92|          66487.79|\n",
      "|  20 to 99 employees|   24677.47|          56113.57|\n",
      "|500 to 999 employees|   27407.43|          58763.03|\n",
      "|10,000 or more em...|   34710.87|          75875.98|\n",
      "|  10 to 19 employees|   21523.31|          53277.85|\n",
      "+--------------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT \n",
    "\tsize, ROUND(AVG(salary), 2) AS `salary mean`,\n",
    "    ROUND(STDDEV(salary), 2)  AS `standard deviation`\n",
    "FROM\n",
    "\t(SELECT \n",
    "\t\tr.id, r.name, ct.name AS `communication_tools`, r.salary, r.company_id \n",
    "\tFROM \n",
    "\t\tresp_tools rt \n",
    "\tINNER JOIN \n",
    "\t\tcommunication_tools ct on rt.communication_tools_id = ct.id \n",
    "\tINNER JOIN \n",
    "\t\trespondent r on rt.respondent_id = r.id) r\n",
    "INNER JOIN company c on r.company_id = c.id\n",
    "WHERE communication_tools = 'Slack'\n",
    "GROUP BY size;\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Qual a diferença entre a média de salário dos respondentes do Brasil que acham que criar código é um hobby e a média de todos de salário de todos os respondentes brasileiros agrupado por cada sistema operacional que eles usam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+------------------------+----------------+\n",
      "|operation_system|brazil salary mean|brazil hobby salary mean|diff salary mean|\n",
      "+----------------+------------------+------------------------+----------------+\n",
      "|     Linux-based|           9831.36|                10141.35|         -309.99|\n",
      "|        BSD/Unix|          90025.22|                90025.22|            0.00|\n",
      "|           MacOS|          10638.05|                10279.19|          358.86|\n",
      "|         Windows|          10634.36|                10567.10|           67.26|\n",
      "+----------------+------------------+------------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "WITH salary_mean AS (\n",
    "    SELECT\n",
    "        os.name AS operation_system, ROUND(AVG(r.salary), 2) AS `salary_mean`\n",
    "    FROM\n",
    "        respondent r \n",
    "    INNER JOIN \n",
    "        country c ON r.country_id = c.id \n",
    "    INNER JOIN\n",
    "        operation_system os ON r.operation_system_id = os.id\n",
    "    WHERE\n",
    "        c.name = 'Brazil'\n",
    "    GROUP BY os.name\n",
    "), hobby_salary_mean AS (\n",
    "    SELECT\n",
    "        os.name AS operation_system, ROUND(AVG(r.salary), 2) AS `salary_mean`\n",
    "    FROM\n",
    "        respondent r \n",
    "    INNER JOIN \n",
    "        country c ON r.country_id = c.id \n",
    "    INNER JOIN\n",
    "        operation_system os ON r.operation_system_id = os.id\n",
    "    WHERE\n",
    "        c.name = 'Brazil' AND r.hobby = TRUE\n",
    "    GROUP BY os.name\n",
    ")\n",
    "SELECT\n",
    "    sm.operation_system, sm.salary_mean AS `brazil salary mean`,\n",
    "    hm.salary_mean AS `brazil hobby salary mean`,\n",
    "    sm.salary_mean - hm.salary_mean AS `diff salary mean`\n",
    "FROM \n",
    "    salary_mean sm \n",
    "JOIN \n",
    "    hobby_salary_mean hm ON sm.operation_system = hm.operation_system;\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Quais são as top 3 tecnologias mais usadas pelos desenvolvedores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|      name|Total users|\n",
      "+----------+-----------+\n",
      "|JavaScript|      54686|\n",
      "|      HTML|      53628|\n",
      "|       CSS|      50979|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT \n",
    "    pl.name, COUNT(rpl.respondent_id) AS `Total users`\n",
    "FROM\n",
    "    resp_programming_language rpl\n",
    "INNER JOIN \n",
    "    programming_language pl ON rpl.programming_language_id = pl.id\n",
    "GROUP BY pl.name\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 3;\n",
    "\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Quais são os top 5 países em questão de salário?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|      country|   salary|\n",
      "+-------------+---------+\n",
      "|     Malaysia|635000.00|\n",
      "|    Argentina|635000.00|\n",
      "|   Bangladesh|635000.00|\n",
      "|United States|635000.00|\n",
      "|     Colombia|635000.00|\n",
      "+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT DISTINCT \n",
    "    c.name AS country, \n",
    "    ROUND(r.salary, 2) AS salary\n",
    "FROM respondent r \n",
    "INNER JOIN \n",
    "    country c ON r.country_id = c.id \n",
    "ORDER BY salary DESC \n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. A tabela abaixo contém os salários mínimos mensais de cinco países presentes na amostra de dados. Baseado nesses valores, gostaríamos de saber quantos usuários ganham mais de 5 salários mínimos em cada um desses países."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+\n",
      "|       Country|GT 5 salaries|\n",
      "+--------------+-------------+\n",
      "| United States|        10148|\n",
      "|         India|         3412|\n",
      "|United Kingdom|          897|\n",
      "|       Germany|          498|\n",
      "|        Canada|          590|\n",
      "+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countries = {\n",
    "    \"United States\": 4787.9,\n",
    "    \"India\": 243.52,\n",
    "    \"United Kingdom\": 6925.63,\n",
    "    \"Germany\": 6664.0,\n",
    "    \"Canada\": 5567.68,\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for country, minimum in countries.items():\n",
    "    dfs.append(\n",
    "        spark.sql(\n",
    "            \"\"\"\n",
    "select \n",
    "\tcount(r.salary) as salary, c.name as country \n",
    "from \n",
    "\trespondent r \n",
    "inner join \n",
    "\tcountry c on r.country_id = c.id \n",
    "where c.name = '{}' and round(r.salary / {}) >= 5\n",
    "group by country;\n",
    "\"\"\".format(\n",
    "                country, minimum\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "spark.createDataFrame(\n",
    "    [(row.country, row.salary) for df in dfs for row in df.collect()],\n",
    "    [\"Country\", \"GT 5 salaries\"],\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ame-data-engineer-challenge-GmjWWdal-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
