{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from core.connection import get_from_database, get_session\n",
    "\n",
    "spark = get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data from database to spark-warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|  default|communications_tools|      false|\n",
      "|  default|             company|      false|\n",
      "|  default|             country|      false|\n",
      "|  default|    operation_system|      false|\n",
      "|  default|programming_language|      false|\n",
      "|  default|resp_programming_...|      false|\n",
      "|  default|          resp_tools|      false|\n",
      "|  default|          respondent|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dw_ame = get_from_database(spark, \"information_schema.tables\")\n",
    "tables = (\n",
    "    dw_ame.select(\"table_name\")\n",
    "    .where(F.col(\"table_schema\") == \"public\")\n",
    "    .rdd.flatMap(lambda x: x)\n",
    "    .collect()\n",
    ")\n",
    "for table in tables:\n",
    "    get_from_database(spark, table).write.saveAsTable(table)\n",
    "\n",
    "spark.sql(\"SHOW TABLES;\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Qual a quantidade de respondentes de cada país?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             country|total|\n",
      "+--------------------+-----+\n",
      "|       United States| 2350|\n",
      "|               India| 1124|\n",
      "|      United Kingdom|  749|\n",
      "|             Germany|  655|\n",
      "|              Canada|  360|\n",
      "|              France|  278|\n",
      "|  Russian Federation|  270|\n",
      "|              Brazil|  255|\n",
      "|              Poland|  233|\n",
      "|               Spain|  203|\n",
      "|           Australia|  194|\n",
      "|         Netherlands|  193|\n",
      "|               Italy|  166|\n",
      "|              Sweden|  129|\n",
      "|             Ukraine|  109|\n",
      "|         Switzerland|  107|\n",
      "|              Israel|  101|\n",
      "|              Turkey|   98|\n",
      "|               China|   92|\n",
      "|Iran, Islamic Rep...|   89|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT \n",
    "    c.name AS country, COUNT(c.name) AS total \n",
    "FROM \n",
    "    respondent r \n",
    "INNER JOIN \n",
    "    country c ON r.country_id = c.id \n",
    "GROUP BY country \n",
    "ORDER BY total DESC;\n",
    "\"\"\"\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Quantos usuários que moram em \"United States\" gostam de Windows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|Windows user's in United States|\n",
      "+-------------------------------+\n",
      "|                            961|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT \n",
    "    count(*) AS `Windows user's in United States`\n",
    "FROM respondent r \n",
    "INNER JOIN \n",
    "    operation_system os ON r.operation_system_id = os.id \n",
    "INNER JOIN \n",
    "    country c ON r.country_id = c.id \n",
    "WHERE c.name = 'United States' AND os.name = 'Windows';\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Qual a média de salário dos usuários que moram em Israel e gostam de Linux?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|Israel linux user's salary mean|\n",
      "+-------------------------------+\n",
      "|                       19278.15|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT \n",
    "    ROUND(AVG(salary), 2) AS `Israel linux user's salary mean`\n",
    "FROM respondent r \n",
    "INNER JOIN \n",
    "    operation_system os ON r.operation_system_id = os.id \n",
    "INNER JOIN \n",
    "    country c ON r.country_id = c.id\n",
    "WHERE c.name = 'Israel' and os.name = 'Linux-based';\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Qual a média e o desvio padrão do salário dos usuários que usam Slack para cada tamanho de empresa disponível?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------------+\n",
      "|                size|salary mean|standard deviation|\n",
      "+--------------------+-----------+------------------+\n",
      "|Fewer than 10 emp...|   24457.96|          54390.66|\n",
      "|100 to 499 employees|   30852.68|          57919.33|\n",
      "|5,000 to 9,999 em...|   30124.88|          61310.04|\n",
      "|1,000 to 4,999 em...|   30821.72|          51641.98|\n",
      "|  20 to 99 employees|   30084.28|          63245.62|\n",
      "|500 to 999 employees|   28238.84|          47406.25|\n",
      "|10,000 or more em...|   38286.31|          77029.57|\n",
      "|  10 to 19 employees|   24472.32|          54963.28|\n",
      "+--------------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT \n",
    "\tsize, ROUND(AVG(salary), 2) AS `salary mean`,\n",
    "    ROUND(STDDEV(salary), 2)  AS `standard deviation`\n",
    "FROM\n",
    "\t(SELECT \n",
    "\t\tr.id, r.name, ct.name AS `communication_tools`, r.salary, r.company_id \n",
    "\tFROM \n",
    "\t\tresp_tools rt \n",
    "\tINNER JOIN \n",
    "\t\tcommunications_tools ct on rt.communications_tools_id = ct.id \n",
    "\tINNER JOIN \n",
    "\t\trespondent r on rt.respondent_id = r.id) r\n",
    "INNER JOIN company c on r.company_id = c.id\n",
    "WHERE communication_tools = 'Slack'\n",
    "GROUP BY size;\n",
    "\"\"\"\n",
    "    ).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ame-data-engineer-challenge-GmjWWdal-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
